{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis of Shiny App A/B Test Data\n",
    "\n",
    "This notebook explores the data collected from our A/B test experiment on the Shiny web application. We'll examine the data structure, distribution of metrics, and perform preliminary analyses to understand patterns and insights."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Add the src directory to path so we can import our modules\n",
    "sys.path.append('..')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the data\n",
    "file_path = '../data/shiny_user_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check data types and missing values\n",
    "df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check distribution of groups\n",
    "group_counts = df['Group'].value_counts()\n",
    "print(\"Group distribution:\")\n",
    "print(group_counts)\n",
    "\n",
    "# Visualize group distribution\n",
    "fig = px.pie(names=group_counts.index, values=group_counts.values, title=\"Group Distribution\")\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Processing Time Spent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Examine the Time_Spent column\n",
    "print(\"Sample Time_Spent values:\")\n",
    "for i in range(3):\n",
    "    print(f\"[{i}] {df['Time_Spent'].iloc[i]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to parse the Time_Spent column\n",
    "def parse_time_spent(time_str):\n",
    "    try:\n",
    "        # Convert string representation of dict to actual dict\n",
    "        time_dict = json.loads(time_str.replace(\"'\", '\"'))\n",
    "        # Return total time across all sections\n",
    "        return sum(time_dict.values())\n",
    "    except (json.JSONDecodeError, AttributeError):\n",
    "        return np.nan\n",
    "\n",
    "# Apply the parser to create a Total_Time_Spent column\n",
    "df['Total_Time_Spent'] = df['Time_Spent'].apply(parse_time_spent)\n",
    "\n",
    "# Extract time spent in individual sections\n",
    "sections = ['data_upload', 'data_cleaning', 'feature_engineering', 'exploratory_analysis']\n",
    "\n",
    "for section in sections:\n",
    "    df[f'Time_{section}'] = df['Time_Spent'].apply(\n",
    "        lambda x: json.loads(x.replace(\"'\", '\"')).get(section, np.nan) \n",
    "        if isinstance(x, str) else np.nan\n",
    "    )\n",
    "\n",
    "# Display the processed data\n",
    "time_cols = ['Total_Time_Spent'] + [f'Time_{s}' for s in sections]\n",
    "df[['User_ID', 'Group'] + time_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics by Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get descriptive statistics by group\n",
    "def get_group_stats(group):\n",
    "    group_df = df[df['Group'] == group]\n",
    "    numeric_cols = group_df.select_dtypes(include=[np.number]).columns\n",
    "    stats_df = group_df[numeric_cols].describe().T\n",
    "    stats_df = stats_df.reset_index().rename(columns={'index': 'metric'})\n",
    "    return stats_df\n",
    "\n",
    "group_a_stats = get_group_stats('A')\n",
    "group_b_stats = get_group_stats('B')\n",
    "\n",
    "print(\"Group A Statistics:\")\n",
    "group_a_stats[['metric', 'count', 'mean', 'std', 'min', 'max']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(\"Group B Statistics:\")\n",
    "group_b_stats[['metric', 'count', 'mean', 'std', 'min', 'max']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot distribution of key metrics\n",
    "key_metrics = [\n",
    "    'Task_Completion_Rate',\n",
    "    'Download_Interaction_Rate',\n",
    "    'Button_Click_Rate',\n",
    "    'Plot_Interactions',\n",
    "    'Total_Time_Spent'\n",
    "]\n",
    "\n",
    "for metric in key_metrics:\n",
    "    fig = px.histogram(\n",
    "        df, \n",
    "        x=metric, \n",
    "        color=\"Group\",\n",
    "        marginal=\"box\",  # Add a box plot on the margin\n",
    "        barmode=\"overlay\",  # Overlay the histograms\n",
    "        title=f\"Distribution of {metric.replace('_', ' ')}\",\n",
    "        opacity=0.7\n",
    "    )\n",
    "    fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Examine correlations between metrics\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr_metrics = [col for col in numeric_cols if col != 'User_ID']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[corr_metrics].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='RdBu_r',\n",
    "    title=\"Correlation Matrix of Metrics\"\n",
    ")\n",
    "fig.update_layout(height=700, width=700)\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preliminary Comparison of Key Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize key metrics by group\n",
    "comparison_data = []\n",
    "\n",
    "for group in ['A', 'B']:\n",
    "    group_df = df[df['Group'] == group]\n",
    "    \n",
    "    for metric in key_metrics:\n",
    "        comparison_data.append({\n",
    "            'Group': group,\n",
    "            'Metric': metric.replace('_', ' '),\n",
    "            'Mean': group_df[metric].mean(),\n",
    "            'StdErr': group_df[metric].std() / np.sqrt(len(group_df))\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "# Create bar chart\n",
    "fig = px.bar(\n",
    "    comparison_df, \n",
    "    x=\"Metric\", \n",
    "    y=\"Mean\", \n",
    "    color=\"Group\",\n",
    "    barmode=\"group\",\n",
    "    error_y=\"StdErr\",\n",
    "    title=\"Comparison of Key Metrics Between Groups\"\n",
    ")\n",
    "fig.update_layout(height=500, width=800)\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Spent Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Analyze time spent in different sections\n",
    "time_sections = [f'Time_{s}' for s in sections]\n",
    "time_data = []\n",
    "\n",
    "for group in ['A', 'B']:\n",
    "    group_df = df[df['Group'] == group]\n",
    "    \n",
    "    for section in time_sections:\n",
    "        clean_name = section.replace('Time_', '').replace('_', ' ').title()\n",
    "        \n",
    "        time_data.append({\n",
    "            'Group': group,\n",
    "            'Section': clean_name,\n",
    "            'Average Time (seconds)': group_df[section].mean()\n",
    "        })\n",
    "\n",
    "time_df = pd.DataFrame(time_data)\n",
    "\n",
    "# Create grouped bar chart\n",
    "fig = px.bar(\n",
    "    time_df,\n",
    "    x='Section',\n",
    "    y='Average Time (seconds)',\n",
    "    color='Group',\n",
    "    barmode='group',\n",
    "    title=\"Average Time Spent in Each Section by Group\"\n",
    ")\n",
    "fig.update_layout(height=500, width=800)\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initial Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Function to perform t-test between groups\n",
    "def run_ttest(metric):\n",
    "    group_a = df[df['Group'] == 'A'][metric].dropna()\n",
    "    group_b = df[df['Group'] == 'B'][metric].dropna()\n",
    "    \n",
    "    if len(group_a) < 2 or len(group_b) < 2:\n",
    "        return f\"Insufficient data for {metric}\"\n",
    "    \n",
    "    t_stat, p_val = stats.ttest_ind(group_a, group_b, equal_var=False)\n",
    "    \n",
    "    return {\n",
    "        'metric': metric,\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_val,\n",
    "        'significant': p_val < 0.05,\n",
    "        'group_a_mean': group_a.mean(),\n",
    "        'group_b_mean': group_b.mean(),\n",
    "        'difference': group_b.mean() - group_a.mean(),\n",
    "        'percent_change': ((group_b.mean() - group_a.mean()) / group_a.mean() * 100) if group_a.mean() != 0 else np.nan,\n",
    "    }\n",
    "\n",
    "# Test all metrics\n",
    "test_results = []\n",
    "for metric in corr_metrics:\n",
    "    result = run_ttest(metric)\n",
    "    if isinstance(result, dict):\n",
    "        test_results.append(result)\n",
    "    else:\n",
    "        print(result)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(test_results)\n",
    "results_df = results_df.sort_values('p_value')\n",
    "\n",
    "# Display results\n",
    "results_df[['metric', 'p_value', 'significant', 'group_a_mean', 'group_b_mean', 'percent_change']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary of Initial Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Filter for significant results\n",
    "significant_results = results_df[results_df['significant']]\n",
    "\n",
    "print(f\"Found {len(significant_results)} significant differences between groups:\")\n",
    "for _, row in significant_results.iterrows():\n",
    "    metric = row['metric'].replace('_', ' ')\n",
    "    change = row['percent_change']\n",
    "    direction = \"higher\" if change > 0 else \"lower\"\n",
    "    print(f\"- {metric}: Group B is {abs(change):.2f}% {direction} than Group A (p={row['p_value']:.4f})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "Based on the exploratory analysis, our next steps will be:\n",
    "\n",
    "1. Refine our statistical testing approach (consider using non-parametric tests for non-normal distributions)\n",
    "2. Develop more detailed visualizations for the key metrics\n",
    "3. Analyze user behavior patterns and engagement funnel\n",
    "4. Prepare the final statistical report with conclusions and recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
